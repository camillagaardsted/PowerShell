{"cells":[{"cell_type":"markdown","id":"1fe7b9dc-60e9-4980-80be-1df16bfd8369","metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"source":["# Foreach and Data Export lab\n","\n","\n","1. Create a list with the numbers from 1 to 10. Store the values in a variable called $numberList\n","2. Write ipaddresses on the screen using foreach. Write all addresses from 172.16.1.1 to 172.16.1.10\n","\n","\n","## Exercise 2\n","1. Connect in a 1:1 session to LON-CL1\n","2. Create a folder on the c drive called DataExport\n","3. Find all users in the AD with a surname and a givenname\n","4. Make a folder for each user called givenname_surname inside the DataExport folder \n","\n","## Exercise 3\n","\n","1. Create a folder on your hyper-v host machine called Data on the C drive\n","1. Find the name and status for all hyper-v machines\n","2. Save the data in a file called hyperv_machines.txt in the Data folder\n","3. Save the same data in a csv file with semicolon as seperator and no type information at the top of the file\n","4. Try to read the machines.txt file with the Get-Content cmdlet.\n","5. Try to import your csv file and make sure you specify the delimiter so PS interprets the objects\n","6. Study with gm the data type for your desirialized objects \n","\n","## Excersise 4\n","1. Find the name, status and dependent services for all services on your machine\n","2. Save the data in the Data folder as a json file\n","3. Try to read the json file into objects in PS\n","\n"]},{"cell_type":"code","execution_count":null,"id":"402c6c82-72d2-475b-b0d9-6ad30457ad1f","metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"outputs":[],"source":["# Welcome to your new notebook\n","# Type here in the cell editor to add code!\n"]}],"metadata":{"dependencies":{},"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"display_name":"synapse_pyspark","name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default"},"widgets":{}},"nbformat":4,"nbformat_minor":5}
